# -*- coding: utf-8 -*-
"""Image_ranking_using_Autoencoders.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Y1Uq5VZ9GH6YsY-L1Ad7ROosI1FINVUo
"""

from google.colab import drive
drive.mount('/content/drive')

"""Base path for project"""

base_path = "/content/drive/MyDrive/USML_Project"

"""Libraries import"""

import keras, tensorflow as tf 
from keras import layers
from keras.utils import load_img, img_to_array
import shutil,csv,os,imageio,PIL,glob
import numpy as np
from PIL import Image, ImageOps
import matplotlib.pyplot as plt
import matplotlib.image as mpimg
import keras.backend as K
from numpy import dot
from numpy.linalg import norm

"""Creating a training set by copying images from photos mapping image file names to different classes. And saving it to a file for later use."""

pending_list = ["canyon","castle","coast","fish","flower","Horses","plane","skyline","sunset","Yosemite"]
train_directory = base_path + "/Train_set/Train_set_rgb"
mapping = []
for item in pending_list:
  directory = base_path + "/photos/" + item
  dir_list = os.listdir(directory)
  for file_t in dir_list:
    if file_t.endswith(".DS_Store"):
      continue
    mapping.append((file_t, item.split("_")[0].lower()))
    new_data = imageio.imread(directory + "/" + file_t)
    imageio.imsave(train_directory + "/" + file_t, new_data)
with open(base_path + '/train_mapping.csv','w', encoding='utf-8') as out:
    csv_out=csv.writer(out)
    csv_out.writerow(['file_name','class'])
    for row in mapping:
        csv_out.writerow(row)

"""Creating a dictionary to map classes with file names, will be used later."""

dictionary = {}
csv_file_path = base_path + "/Train_set/train_mapping.csv"
mapping = []
with open(csv_file_path, newline='') as csvfile:
    reader = csv.reader(csvfile)
    counter = 0
    for row in reader:
        if counter == 0:
          counter += 1
          continue
        dictionary.setdefault(row[1],set()).add(row[0])

print(dictionary)

"""Loading mapping from saved mappings"""

csv_file_path = base_path + "/train_mapping.csv"
mapping = []
with open(csv_file_path, newline='') as csvfile:
    reader = csv.reader(csvfile)
    counter = 0
    for row in reader:
        if counter == 0:
          counter += 1
          continue
        mapping.append((row[0],row[1]))

"""Generating train set by reading images and converting them to vectors."""

train_x_set = []
train_y_set = []
train_directory = base_path + "/Train_set/Train_set_rgb"
for item in mapping:
  file_name , cls = item
  directory = train_directory + "/" + file_name
  image = load_img(directory)
  img_array = img_to_array(image)
  train_x_set.append(img_array)
  train_y_set.append(cls)

"""Saving array representations on disk to be used later."""

with open(base_path + "/train_x_dataset_rgb",'wb') as out:
    np.save(out, train_x_set)

with open(base_path + "/train_y_dataset_rgb",'wb') as out:
    np.save(out,train_y_set)

"""Function to load train dataset"""

def load_local_train_dataset():
  train_x = []
  train_y = []
  with open(base_path + "/train_x_dataset_rgb",'rb') as out:
      train_x = np.load(out)

  with open(base_path + "/train_y_dataset_rgb",'rb') as out:
      train_y = np.load(out)
  return np.array(train_x),np.array(train_y)

"""Loading training data"""

train_x_set,train_y_set = load_local_train_dataset()

train_x_set.shape

train_x_set[0].shape

train_x_set[0].shape

"""Building autoencoder model using keras Sequential"""

autoencoder_rgb = keras.Sequential([
    layers.Input(shape=(256,256,3)),
    layers.Conv2D(64,(4,4),padding='same',activation='relu'),
    layers.MaxPooling2D((2,2), padding='same'),
    layers.Conv2D(32,(4,4),padding='same',activation='relu'),
    layers.MaxPooling2D((2,2), padding='same'),
    layers.Conv2D(16,(4,4),padding='same',activation='relu'),
    layers.MaxPooling2D((2,2), padding='same'),
    layers.Conv2D(8,(4,4),padding='same',activation='relu'),
    layers.MaxPooling2D((2,2), padding='same'),
    layers.Conv2DTranspose(8,(4,4),padding='same',activation='relu'),
    layers.UpSampling2D((2,2)),
    layers.Conv2DTranspose(16,(4,4),padding='same',activation='relu'),
    layers.UpSampling2D((2,2)),
    layers.Conv2DTranspose(32,(4,4),padding='same',activation='relu'),
    layers.UpSampling2D((2,2)),
    layers.Conv2DTranspose(64,(4,4),padding='same',activation='relu'),
    layers.UpSampling2D((2,2)),
    layers.Conv2DTranspose(3,(4,4), padding='same'),
]);

"""Used only when loading the saved state of the model"""

autoencoder_rgb = keras.models.load_model(base_path+"/rgb_model")

"""structure of the model"""

autoencoder_rgb.summary()

"""compiling model with MSE as loss and adam optimizer"""

autoencoder_rgb.compile(loss='mse', optimizer='adam')

"""Creating a callback for early stopping of training"""

from keras.callbacks import EarlyStopping
early_stop = EarlyStopping(monitor='val_loss',min_delta=0, patience=10, verbose=1,mode='auto')

"""Training the model"""

import  tensorflow as tf
tf.config.run_functions_eagerly(True)
history = autoencoder_rgb.fit(train_x_set, train_x_set, epochs=100, callbacks=[early_stop], validation_split=0.1)

"""Saving the model on to disk"""

autoencoder_rgb.save(base_path+"/rgb_model")

"""Plotting decoder output for one train image"""

plot_image(autoencoder_rgb.predict(train_x_set[:1000])[700])

"""Plotting actual image"""

plot_image(train_x_set[700])

"""defining utility functions"""

def plot_image(image):
  plt.imshow(image.astype("uint8"), cmap='binary')
  plt.axis('off')

def show_reconstruction(model,data_set, n_image=5):
  reconstructions = model.predict(data_set[:n_image])

  plt.figure(figsize=(n_image * 5, 10))
  for image_idx in range(n_image):
    plt.subplot(2,n_image, image_idx + 1)
    plot_image(data_set[image_idx].reshape(256,256,3))
    plt.subplot(2, n_image, n_image + image_idx + 1)
    plot_image(reconstructions[image_idx])

def plot_images(array):
  n_image = len(array)
  plt.figure(figsize=(n_image * 5, 15))
  for idx in range(len(array)):
    img = array[idx]
    path = base_path + "/" + img[1] + "/" + img[2]
    plt.subplot(2, n_image/2, idx+1)
    img = mpimg.imread(path)
    imgplot = plt.imshow(img)
    # plt.show()
    plt.axis('off')

"""Creating utility functions for extracting feature vector that will be used as inverted index of test images."""

base_path = "/content/drive/MyDrive/USML_Project/Test_set"
classes = ["canyon","castle","coast","fish","flower","horses","plane","skyline","sunset","yosemite"]
inverted_index = []

def get_image_as_array(path):
  image = load_img(path)
  img_array = img_to_array(image)
  img_array = [img_array]
  img_array = np.array(img_array)
  img_array = img_array.reshape(-1, 256, 256, 3)
  return img_array

def get_vector(img_array):
  get_all_layer_outputs = K.function([autoencoder_rgb.layers[0].input],
                                  [l.output for l in autoencoder_rgb.layers[1:]])
  layer_output = get_all_layer_outputs([img_array])
  return layer_output[7].flatten()

"""Calculating inverted indices of all the test images"""

for item in classes:
  directory_path = base_path + "/" + item
  for file_t in os.listdir(directory_path):
    img_array = get_image_as_array(directory_path + "/" + file_t)
    vector = get_vector(img_array)
    inverted_index.append((vector, item, file_t))

"""saving inverted index to file"""

with open(base_path + '/inverted_index.csv','w', encoding='utf-8') as out:
    csv_out=csv.writer(out, delimiter=";")
    csv_out.writerow(['vector','class','file_name'])
    for row in inverted_index:
        v = ",".join(map(str, row[0].tolist()))
        # v = ",".join(row[0].tolist())
        csv_out.writerow([v, row[1],row[2]])

"""loading inverted indices from csv"""

csv_file_path = base_path + "/Test_set/inverted_index.csv"
inverted_index_read = []
with open(csv_file_path, newline='') as csvfile:
    reader = csv.reader(csvfile, delimiter=";")
    counter = 0
    for row in reader:
        if counter == 0:
          counter += 1
          continue
        vector = row[0].split(",")
        vector = [float(i) for i in vector]
        inverted_index_read.append((vector,row[1],row[2]))

"""Defining cosine similarity function"""

def cosine_sim(a,b):
  cos_sim = dot(a, b)/(norm(a)*norm(b))
  return cos_sim

"""Defining function to ranking images on query and fetch top n items"""

def get_top_images(query_v,n_images=10):
  ranking_list = []
  for row in inverted_index_read:
    c_sim = cosine_sim(query_v, row[0])
    ranking_list.append((c_sim, row[1], row[2]))
  
  ranking_list = sorted(ranking_list,key=lambda x: x[0], reverse=True)
  return ranking_list[:n_images]

"""Loading query image for Castle"""

train_directory = "/content/drive/MyDrive/USML_Project"
query_img_path = train_directory + "/photos/castle/34403103904_9e829d548b_b.jpg"
query_img = get_image_as_array(query_img_path)
query_vector = get_vector(query_img)
query_vector = query_vector.tolist()
plot_image(query_img.reshape(256,256,3))

"""Fetching top ten results for Castle"""

result = get_top_images(query_vector, n_images = 10)
result

plot_images(result)

"""Precision @10 = 6/10

Loading query image for plane
"""

train_directory = "/content/drive/MyDrive/USML_Project"
query_img_path = train_directory + "/photos/plane/27111282547_57c0757e7a_b.jpg"
query_img = get_image_as_array(query_img_path)
query_vector = get_vector(query_img)
query_vector = query_vector.tolist()
plot_image(query_img.reshape(256,256,3))

result = get_top_images(query_vector, n_images = 10)
result

plot_images(result)

"""Precision @10 = 10/10

Loading query image for canyon
"""

train_directory = "/content/drive/MyDrive/USML_Project"
query_img_path = train_directory + "/photos/canyon/27657642367_21a8409a11_b.jpg"
query_img = get_image_as_array(query_img_path)
query_vector = get_vector(query_img)
query_vector = query_vector.tolist()
plot_image(query_img.reshape(256,256,3))

"""Fetching top ten results for Canyon"""

result = get_top_images(query_vector, n_images = 10)
result

plot_images(result)

"""Precision @10 = 7/10

Loading query image for sunset
"""

train_directory = "/content/drive/MyDrive/USML_Project"
query_img_path = train_directory + "/photos/sunset/34105340450_8aa36d5319_b.jpg"
query_img = get_image_as_array(query_img_path)
query_vector = get_vector(query_img)
query_vector = query_vector.tolist()
plot_image(query_img.reshape(256,256,3))

"""Fetching top ten results for Sunset"""

result = get_top_images(query_vector, n_images = 10)
result

plot_images(result)

"""Precision @10 = 10/10

Loading query image for Yosemite
"""

train_directory = "/content/drive/MyDrive/USML_Project"
query_img_path = train_directory + "/photos/Yosemite/23473046368_f487a8effa_b.jpg"
query_img = get_image_as_array(query_img_path)
query_vector = get_vector(query_img)
query_vector = query_vector.tolist()
plot_image(query_img.reshape(256,256,3))

"""Fetching top ten results for Yosemite"""

result = get_top_images(query_vector, n_images = 10)
result

plot_images(result)

"""Precision @10 = 2/10

Loading query image for Horses
"""

train_directory = "/content/drive/MyDrive/USML_Project"
query_img_path = train_directory + "/photos/Horses/27960469738_5270859e5c_b.jpg"
query_img = get_image_as_array(query_img_path)
query_vector = get_vector(query_img)
query_vector = query_vector.tolist()
plot_image(query_img.reshape(256,256,3))

"""Fetching top ten results for Horses"""

result = get_top_images(query_vector, n_images = 10)
result

plot_images(result)

"""Precision @10 = 7/10

Loading query image for flower
"""

train_directory = "/content/drive/MyDrive/USML_Project"
query_img_path = train_directory + "/photos/flower/25789056418_2536536e75_b.jpg"
query_img = get_image_as_array(query_img_path)
query_vector = get_vector(query_img)
query_vector = query_vector.tolist()
plot_image(query_img.reshape(256,256,3))

"""Fetching top ten results for Flower"""

result = get_top_images(query_vector, n_images = 10)
result

plot_images(result)

"""Precision @10 = 4/10

Loading query image for skyline
"""

train_directory = "/content/drive/MyDrive/USML_Project"
query_img_path = train_directory + "/photos/skyline/27301864387_43a7103e27_b.jpg"
query_img = get_image_as_array(query_img_path)
query_vector = get_vector(query_img)
query_vector = query_vector.tolist()
plot_image(query_img.reshape(256,256,3))

"""Fetching top ten results for skyline"""

result = get_top_images(query_vector, n_images = 10)
result

plot_images(result)

"""Precision @10 = 9/10

Loading query image for coast
"""

train_directory = "/content/drive/MyDrive/USML_Project"
query_img_path = train_directory + "/photos/coast/25284499637_1bd4ac8fd5_b.jpg"
query_img = get_image_as_array(query_img_path)
query_vector = get_vector(query_img)
query_vector = query_vector.tolist()
plot_image(query_img.reshape(256,256,3))

"""Fetching top ten results for coast"""

result = get_top_images(query_vector, n_images = 10)
result

plot_images(result)

"""Precision @10 = 5/10

Loading query image for fish
"""

train_directory = "/content/drive/MyDrive/USML_Project"
query_img_path = train_directory + "/photos/fish/24708571066_c8e2f3fcdd_b.jpg"
query_img = get_image_as_array(query_img_path)
query_vector = get_vector(query_img)
query_vector = query_vector.tolist()
plot_image(query_img.reshape(256,256,3))

"""Fetching top ten results for fish"""

result = get_top_images(query_vector, n_images = 10)
result

plot_images(result)

"""Precision @10 = 3/10"""